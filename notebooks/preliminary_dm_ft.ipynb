{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### use Fitzpatrick17k as an example\n",
    "\n",
    "condition_list = ['acne',\n",
    "                'actinic_keratosis',\n",
    "                'allergic_contact_dermatitis',\n",
    "                'basal_cell_carcinoma',\n",
    "                'eczema',\n",
    "                'erythema_multiforme',\n",
    "                'folliculitis',\n",
    "                'granuloma_annulare',\n",
    "                'keloid',\n",
    "                'lichen_planus',\n",
    "                'lupus_erythematosus',\n",
    "                'melanoma',\n",
    "                'mycosis_fungoides',\n",
    "                'pityriasis_rosea',\n",
    "                'prurigo_nodularis',\n",
    "                'psoriasis',\n",
    "                'sarcoidosis',\n",
    "                'scabies',\n",
    "                'squamous_cell_carcinoma',\n",
    "                'vitiligo']\n",
    "\n",
    "MODEL_NAME=\"stabilityai/stable-diffusion-2-1-base\"\n",
    "TRAIN_DIR=\"/data/derm_data/Fitzpatrick17k/finalfitz17k/\" # image folder\n",
    "TRAIN_SPLIT='../splits/Fitzpatrick17k/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Textual Inversion \n",
    "\n",
    "for c in condition_list:\n",
    "    OUTPUT_DIR=f\"../models/textual_inversion_weights/fitzpatrick17k/{c}\" \n",
    "    TOKEN=f'xxx{c[:3]}xxx'\n",
    "\n",
    "    !accelerate launch ../scripts/textual_inversion.py \\\n",
    "        --pretrained_model_name_or_path=$MODEL_NAME \\\n",
    "        --train_data_dir=$TRAIN_DIR \\\n",
    "        --train_data_split=$TRAIN_SPLIT \\\n",
    "        --learnable_property=\"object\" \\\n",
    "        --placeholder_token=$TOKEN \\\n",
    "        --initializer_token=\"skin\" \\\n",
    "        --resolution=512 \\\n",
    "        --train_batch_size=4 \\\n",
    "        --gradient_accumulation_steps=4 \\\n",
    "        --max_train_steps=500 \\   \n",
    "        --learning_rate=5.0e-04 \\\n",
    "        --scale_lr \\\n",
    "        --lr_scheduler=\"constant\" \\\n",
    "        --lr_warmup_steps=0 \\\n",
    "        --output_dir=$OUTPUT_DIR \\\n",
    "        --class_name=$c \\\n",
    "        --repeats=1 \\\n",
    "        #   --push_to_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge all the learned embeddings into a single torch model\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import torch\n",
    "from safetensors import safe_open\n",
    "from safetensors.torch import save_file\n",
    "\n",
    "TI_OUTPUT_DIR = \"../models/textual_inversion_weights/fitzpatrick17k\"\n",
    "path = f\"{TI_OUTPUT_DIR}/*/learned_embeds.safetensors\"\n",
    "merged_dict = dict()\n",
    "for file in glob.glob(path):\n",
    "    tensors = {}\n",
    "    with safe_open(file, framework=\"pt\", device=\"cpu\") as f:\n",
    "        for key in f.keys():\n",
    "            tensors[key] = f.get_tensor(key)\n",
    "        merged_dict.update(tensors)\n",
    "\n",
    "TI_EMBED_PATH = f\"{TI_OUTPUT_DIR}/aggregated_embed_sd2_1_base.pt\"\n",
    "os.makedirs(os.path.dirname(TI_EMBED_PATH), exist_ok=True)\n",
    "torch.save(merged_dict, TI_EMBED_PATH)\n",
    "\n",
    "print(merged_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### for lora training, we use a json file to manage the training data with images and prompts\n",
    "### note that, here, we should put the learned lesion token names derived from textual inversion\n",
    "### in the prompts, instead of the original disease names. Feel free to try different rank sizes.\n",
    "\n",
    "LORA_OUTPUT_DIR=\"/media/janet/DermDPO/models/lora_weights/fitzpatrick17k\"\n",
    "json_path = \"../splits/Fitzpatrick17k/fitzpatrick17k.json\"\n",
    "\n",
    "!accelerate launch --mixed_precision=\"fp16\"  ../scripts/train_text_to_image_lora.py \\\n",
    "    --pretrained_model_name_or_path=$MODEL_NAME \\\n",
    "    --train_data_dir=$TRAIN_DIR \\\n",
    "    --dataloader_num_workers=8 \\\n",
    "    --image_column=\"image\" \\\n",
    "    --caption_column=\"prompt\" \\\n",
    "    --resolution=512 \\\n",
    "    --center_crop \\\n",
    "    --random_flip \\\n",
    "    --train_batch_size=4 \\\n",
    "    --gradient_accumulation_steps=1 \\\n",
    "    --max_train_steps=3000 \\\n",
    "    --learning_rate=5e-06 \\\n",
    "    --max_grad_norm=1 \\\n",
    "    --lr_scheduler=\"cosine\" \\\n",
    "    --lr_warmup_steps=0 \\\n",
    "    --output_dir=$LORA_OUTPUT_DIR \\\n",
    "    --report_to=wandb \\\n",
    "    --checkpointing_steps=1000 \\\n",
    "    --seed=1337 \\\n",
    "    --rank=32 \\\n",
    "    --embed_path=$TI_EMBED_PATH \\\n",
    "    --json_path=$json_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
