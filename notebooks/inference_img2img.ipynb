{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms, models\n",
    "\n",
    "# import skimagea``\n",
    "# from skimage import io\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import torch\n",
    "# from pipeline import StableDiffusionPipeline\n",
    "from diffusers import UNet2DConditionModel, StableDiffusionImg2ImgPipeline, StableDiffusionPipeline\n",
    "\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)  \n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 6/6 [00:00<00:00, 27.18it/s]\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"stabilityai/stable-diffusion-2-1-base\" \n",
    "\n",
    "pipe = StableDiffusionImg2ImgPipeline.from_pretrained(MODEL_NAME, \n",
    "                                                      torch_dtype=torch.float32, \n",
    "                                                    #   revision=\"fp16\"\n",
    "                                                      ).to('cuda:0')\n",
    "pipe.safety_checker = None\n",
    "pipe.requires_safety_checker = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/DermDPO/pretrained_weights/ti_output_20class_selected_0.5_ratio_3100/aggregated_embed_sd2_1_base.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/janet/miniconda3/envs/diff3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1852: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/home/janet/miniconda3/envs/diff3/lib/python3.12/site-packages/transformers/modeling_utils.py:4632: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49428\n"
     ]
    }
   ],
   "source": [
    "from transformers import CLIPTokenizer, CLIPTextModel\n",
    "\n",
    "def load_embeddings(embed_path: str, \n",
    "                    model_path: str = \"stabilityai/stable-diffusion-2-1-base\"\n",
    "                    ):\n",
    "\n",
    "    tokenizer = CLIPTokenizer.from_pretrained(\n",
    "        model_path, use_auth_token=True,\n",
    "        subfolder=\"tokenizer\")\n",
    "\n",
    "    text_encoder = CLIPTextModel.from_pretrained(\n",
    "        model_path, use_auth_token=True,\n",
    "        subfolder=\"text_encoder\")\n",
    "    \n",
    "    print(len(tokenizer))\n",
    "\n",
    "    for token, token_embedding in torch.load(\n",
    "            embed_path, map_location=\"cpu\").items():\n",
    "\n",
    "        # add the token in tokenizer\n",
    "        num_added_tokens = tokenizer.add_tokens(token)\n",
    "        assert num_added_tokens > 0\n",
    "\n",
    "        # resize the token embeddings\n",
    "        text_encoder.resize_token_embeddings(len(tokenizer))\n",
    "        added_token_id = tokenizer.convert_tokens_to_ids(token)\n",
    "\n",
    "        # get the old word embeddings\n",
    "        embeddings = text_encoder.get_input_embeddings()\n",
    "\n",
    "        # get the id for the token and assign new embeds\n",
    "        embeddings.weight.data[added_token_id] = \\\n",
    "            token_embedding.to(embeddings.weight.dtype)\n",
    "    print(len(tokenizer))\n",
    "\n",
    "    return tokenizer, text_encoder.to('cuda:0')\n",
    "\n",
    "### add textual inversion tokens\n",
    "embed_path = f'/data/DermDPO/pretrained_weights/ti_output_20class_selected_0.5_ratio_3100/aggregated_embed_sd2_1_base.pt'\n",
    "print(embed_path)\n",
    "tokenizer, text_encoder = load_embeddings(\n",
    "                embed_path, model_path=MODEL_NAME)\n",
    "pipe.tokenizer = tokenizer\n",
    "pipe.text_encoder = text_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "prompt_mapping = {\n",
    "                0: 'xxxacnxxx',\n",
    "                1: 'xxxactxxx',\n",
    "                2: 'xxxallxxx',\n",
    "                3: 'xxxbasxxx',\n",
    "                4: 'xxxeczxxx',\n",
    "                5: 'xxxeryxxx',\n",
    "                6: 'xxxfolxxx',\n",
    "                7: 'xxxgraxxx',\n",
    "                8: 'xxxkelxxx',\n",
    "                9: 'xxxlicxxx',\n",
    "                10: 'xxxlupxxx',\n",
    "                11: 'xxxmelxxx',\n",
    "                12: 'xxxmycxxx',\n",
    "                13: 'xxxpitxxx',\n",
    "                14: 'xxxpruxxx',\n",
    "                15: 'xxxpsoxxx',\n",
    "                16: 'xxxsarxxx',\n",
    "                17: 'xxxscaxxx',\n",
    "                18: 'xxxsquxxx',\n",
    "                19: 'xxxvitxxx'\n",
    "                }\n",
    "\n",
    "mapping = {\n",
    "            0: 'acne',\n",
    "            1: 'actinic keratosis',\n",
    "            2: 'allergic contact dermatitis',\n",
    "            3: 'basal cell carcinoma',\n",
    "            4: 'eczema',\n",
    "            5: 'erythema multiforme',\n",
    "            6: 'folliculitis',\n",
    "            7: 'granuloma annulare',\n",
    "            8: 'keloid',\n",
    "            9: 'lichen planus',\n",
    "            10: 'lupus erythematosus',\n",
    "            11: 'melanoma',\n",
    "            12: 'mycosis fungoides',\n",
    "            13: 'pityriasis rosea',\n",
    "            14: 'prurigo nodularis',\n",
    "            15: 'psoriasis',\n",
    "            16: 'sarcoidosis',\n",
    "            17: 'scabies',\n",
    "            18: 'squamous cell carcinoma',\n",
    "            19: 'vitiligo'\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No LoRA keys associated to UNet2DConditionModel found with the prefix='unet'. This is safe to ignore if LoRA state dict didn't originally have any UNet2DConditionModel related params. You can also try specifying `prefix=None` to resolve the warning. Otherwise, open an issue if you think it's unexpected: https://github.com/huggingface/diffusers/issues/new\n",
      "No LoRA keys associated to CLIPTextModel found with the prefix='text_encoder'. This is safe to ignore if LoRA state dict didn't originally have any CLIPTextModel related params. You can also try specifying `prefix=None` to resolve the warning. Otherwise, open an issue if you think it's unexpected: https://github.com/huggingface/diffusers/issues/new\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StableDiffusionImg2ImgPipeline {\n",
       "  \"_class_name\": \"StableDiffusionImg2ImgPipeline\",\n",
       "  \"_diffusers_version\": \"0.34.0\",\n",
       "  \"_name_or_path\": \"stabilityai/stable-diffusion-2-1-base\",\n",
       "  \"feature_extractor\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPImageProcessor\"\n",
       "  ],\n",
       "  \"image_encoder\": [\n",
       "    null,\n",
       "    null\n",
       "  ],\n",
       "  \"requires_safety_checker\": false,\n",
       "  \"safety_checker\": [\n",
       "    null,\n",
       "    null\n",
       "  ],\n",
       "  \"scheduler\": [\n",
       "    \"diffusers\",\n",
       "    \"PNDMScheduler\"\n",
       "  ],\n",
       "  \"text_encoder\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTextModel\"\n",
       "  ],\n",
       "  \"tokenizer\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTokenizer\"\n",
       "  ],\n",
       "  \"unet\": [\n",
       "    \"diffusers\",\n",
       "    \"UNet2DConditionModel\"\n",
       "  ],\n",
       "  \"vae\": [\n",
       "    \"diffusers\",\n",
       "    \"AutoencoderKL\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dir = '/data/derm_data/Fitzpatrick17k/finalfitz17k'\n",
    "\n",
    "### load model after MAGIC-DPO\n",
    "lora_path = f'/data/DermDPO/logs/fitz_20class_3100_w_bodyparts_new_cklist_2025.04.27_20.36.50/checkpoints/checkpoint_20'\n",
    "output = f'output' # output path\n",
    "\n",
    "os.makedirs(output, exist_ok=True)\n",
    "pipe.load_lora_weights(lora_path)\n",
    "pipe.to(dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:01<00:00, 15.60it/s]\n",
      "100%|██████████| 30/30 [00:01<00:00, 15.39it/s]\n",
      "100%|██████████| 30/30 [00:01<00:00, 15.21it/s]\n",
      "100%|██████████| 30/30 [00:01<00:00, 15.14it/s]\n",
      "100%|██████████| 30/30 [00:01<00:00, 15.14it/s]\n",
      "100%|██████████| 30/30 [00:01<00:00, 15.03it/s]\n",
      "100%|██████████| 30/30 [00:02<00:00, 14.92it/s]\n",
      "100%|██████████| 30/30 [00:02<00:00, 14.85it/s]\n",
      "100%|██████████| 30/30 [00:02<00:00, 14.76it/s]\n",
      "100%|██████████| 30/30 [00:02<00:00, 14.68it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>md5hash</th>\n",
       "      <th>original_class</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9bba5f64da2feb5a8233e53b418bd4e8_11</td>\n",
       "      <td>acne</td>\n",
       "      <td>melanoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76e0c1c6f1279c4f61527c16fc921e2b_9</td>\n",
       "      <td>acne</td>\n",
       "      <td>lichen planus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2ed5843cc88e0bf7c199a2cf811acec9_5</td>\n",
       "      <td>acne</td>\n",
       "      <td>erythema multiforme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dc9fc1c8428e390e6f790e19d24c4e4a_7</td>\n",
       "      <td>acne</td>\n",
       "      <td>granuloma annulare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6372c52836107dd23cff2f8c972353ef_11</td>\n",
       "      <td>acne</td>\n",
       "      <td>melanoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>e0596e8822027374d0a1582ce7461eff_4</td>\n",
       "      <td>acne</td>\n",
       "      <td>eczema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>e95dc7cb6e69674a28b19ee6888090f9_3</td>\n",
       "      <td>acne</td>\n",
       "      <td>basal cell carcinoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>68294e8f4f456ad4395c6eb57237f584_13</td>\n",
       "      <td>acne</td>\n",
       "      <td>pityriasis rosea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17baabbf21b092bdfc4a5c35c9457686_4</td>\n",
       "      <td>acne</td>\n",
       "      <td>eczema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>811f74634ec6dd7022aa04e4968fea38_12</td>\n",
       "      <td>acne</td>\n",
       "      <td>mycosis fungoides</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               md5hash original_class                 label\n",
       "0  9bba5f64da2feb5a8233e53b418bd4e8_11           acne              melanoma\n",
       "1   76e0c1c6f1279c4f61527c16fc921e2b_9           acne         lichen planus\n",
       "2   2ed5843cc88e0bf7c199a2cf811acec9_5           acne   erythema multiforme\n",
       "3   dc9fc1c8428e390e6f790e19d24c4e4a_7           acne    granuloma annulare\n",
       "4  6372c52836107dd23cff2f8c972353ef_11           acne              melanoma\n",
       "5   e0596e8822027374d0a1582ce7461eff_4           acne                eczema\n",
       "6   e95dc7cb6e69674a28b19ee6888090f9_3           acne  basal cell carcinoma\n",
       "7  68294e8f4f456ad4395c6eb57237f584_13           acne      pityriasis rosea\n",
       "8   17baabbf21b092bdfc4a5c35c9457686_4           acne                eczema\n",
       "9  811f74634ec6dd7022aa04e4968fea38_12           acne     mycosis fungoides"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_path = '/media/janet/DermDPO/magic_pytorch/assets/all_prompts.json'\n",
    "\n",
    "with open(metadata_path, 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "res = []\n",
    "for data in metadata:\n",
    "    image_path = data['image_path']\n",
    "    img_id = data['image_path'].split('.')[0].split('/')[-1]\n",
    "    \n",
    "    original_class = data['label']\n",
    "    \n",
    "    try:\n",
    "        target_class = random.choice([\n",
    "            x for x in range(20)\n",
    "            if mapping[x] != original_class\n",
    "            and any(part in body_part_dist[mapping[x]] for part in gross_body_part)\n",
    "        ])\n",
    "    except:\n",
    "        target_class = random.choice([\n",
    "            x for x in range(20)\n",
    "            if mapping[x] != original_class\n",
    "        ])\n",
    "    target_label = mapping[target_class]\n",
    "        \n",
    "    d_type = prompt_mapping[target_class]\n",
    "    \n",
    "    img = Image.open(f'{image_dir}/{image_path}').convert(\"RGB\")\n",
    "    img = img.resize((512, 512), resample=PIL.Image.BILINEAR)\n",
    "    \n",
    "    images = pipe(\n",
    "        prompt=f\"an image of {d_type} on human skin\",  # {d_type} around {body_part} of a person\n",
    "        image=img, \n",
    "        strength=0.3, # default: 0.8\n",
    "        num_inference_steps=100,\n",
    "        guidance_scale=5, # default: 7.5\n",
    "        num_images_per_prompt=1,\n",
    "    ).images\n",
    "    \n",
    "    # idx = 0\n",
    "    for image in images:\n",
    "        name = f\"{img_id}_{target_class}\"\n",
    "        resized_img = image.resize(size=(256, 256))\n",
    "        resized_img.save(f'{output}/{name}.png')\n",
    "        res.append([name, original_class, target_label])\n",
    "        # idx += 1\n",
    "            \n",
    "        \n",
    "synthetic_train = pd.DataFrame(res, columns=['md5hash', 'original_class', 'label'])\n",
    "synthetic_train.to_csv(f'output.csv', index=False)\n",
    "synthetic_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
